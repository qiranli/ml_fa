{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your WRDS username [liqiran]:ansonccy\n",
      "Enter your password:········\n",
      "WRDS recommends setting up a .pgpass file.\n",
      "You can find more info here:\n",
      "https://www.postgresql.org/docs/9.5/static/libpq-pgpass.html.\n",
      "Loading library list...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Builds the fundamental dataset for top 2000 market cap equitities from WRDS.\n",
    "Requires WRDS account. Enter username and password when prompted.\n",
    "\n",
    "Features: datadate,\tgvkey,\tyear,  month,  mom1m,\tmom3m,\tmom6m,\tmom9m,\n",
    "        mrkcap,\tentval,\tsaleq_ttm,\tcogsq_ttm,\txsgaq_ttm,\toiadpq_ttm,\n",
    "        niq_ttm,\tcheq_mrq,\trectq_mrq,\tinvtq_mrq,\tacoq_mrq,\n",
    "        ppentq_mrq,\taoq_mrq,\tdlcq_mrq,\tapq_mrq,\ttxpq_mrq,\n",
    "            lcoq_mrq,   ltq_mrq,\tcsho_1yr_avg,GSECTOR,GSUBIND \n",
    "\n",
    "Takes about 1.5 minutes to build the complete dataset and outputs a csv\n",
    "\"\"\"\n",
    "\n",
    "import wrds\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pickle\n",
    "from time import time\n",
    "from wrds_data_processing import data_processing\n",
    "import sys\n",
    "\n",
    "start_time = time()\n",
    "\n",
    "# Connect to WRDS data engine\n",
    "db = wrds.Connection()\n",
    "\n",
    "#############################################################################\n",
    "#### SQL Query-----------------------------------------------------------####\n",
    "#############################################################################\n",
    "\n",
    "# Query to get list of companies with top 20 market cap\n",
    "q1 = (\"select a.gvkey,a.latest,b.cshoq,b.prccq,b.mkvaltq,b.cshoq*b.prccq as market_cap,b.curcdq \"\n",
    "     \"from \"\n",
    "        \"(select gvkey,max(datadate) as latest \"\n",
    "         \"from \"\n",
    "         \"compm.fundq where datadate > '2017-01-01' \"\n",
    "         \"group by gvkey) a inner join \"\n",
    "             \"(select gvkey,datadate,mkvaltq,cshoq,prccq,curcdq \"\n",
    "                \"from compm.fundq where cshoq>0 and prccq>0 and curcdq='USD') b \"\n",
    "    \"on a.gvkey = b.gvkey and a.latest=b.datadate \"\n",
    "     \"order by market_cap desc \"\n",
    "    \"limit 20\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of raw dataframe: 2863,43\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mrk_df = db.raw_sql(q1)\n",
    "top_20_eq_gvkey_list = mrk_df['gvkey'].values.tolist()\n",
    "top_20_eq_gvkey = tuple([\"'%s'\"%str(i) for i in top_20_eq_gvkey_list])\n",
    "top_20_eq_gvkey = \",\".join(top_20_eq_gvkey)\n",
    "\n",
    "\n",
    "# Query to get fundamental Data\n",
    "q2 = (\"select datadate,gvkey,tic,saleq,cogsq,xsgaq,oiadpq,niq,revtq,oibdpq,xintq,nopiq,spiq,piq,txtq,ibq,epspxq,epsfxq,\"\n",
    "      \"cheq, rectq, invtq, acoq, actq, ppentq, ivaeqq, ivaoq, intanq, aoq, atq, dlcq, apq, txpq,\"\n",
    "      \"lcoq, lctq, dlttq, txditcq, loq, ltq, mibq,\"\n",
    "      \"pstkq , ceqq, seqq, cshoq \"\n",
    "      \"from compm.fundq \"\n",
    "      \"where gvkey in (%s) \")%top_20_eq_gvkey\n",
    "fundq_df = db.raw_sql(q2)\n",
    "\n",
    "print(\"Shape of raw dataframe: %g,%g\"%fundq_df.shape)\n",
    "print('\\n')\n",
    "\n",
    "# Query to get price data\n",
    "q3 = (\"select gvkey,datadate,prccm \"\n",
    "     \"from compm.secm \"\n",
    "     \"where gvkey in (%s) \")%top_20_eq_gvkey\n",
    "price_df_all = db.raw_sql(q3).sort_values('datadate')\n",
    "\n",
    "# Query to get stock_split data\n",
    "q4 = (\"select gvkey,datadate,split \"\n",
    "     \"from compm.sec_split \"\n",
    "     \"where gvkey in (%s) \")%top_20_eq_gvkey\n",
    "stock_split_df_all = db.raw_sql(q4).sort_values('datadate')\n",
    "####--------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "# Build balance sheet features\n",
    "blnc_sheet_list = ['cheq','rectq','invtq','acoq','actq','ppentq','ivaeqq','ivaoq','intanq','aoq','atq',\n",
    "                                'dlcq','apq','txpq','lcoq','lctq','dlttq','txditcq','loq','ltq','mibq',\n",
    "                   'pstkq','ceqq','seqq','cshoq']\n",
    "\n",
    "# Build income sheet features\n",
    "income_list = ['saleq','cogsq','xsgaq','oiadpq','niq','revtq','xintq','nopiq','spiq',\n",
    "               'piq','txtq','ibq','epspxq','epsfxq']\n",
    "\n",
    "\n",
    "gvkey_list = top_20_eq_gvkey_list\n",
    "print len(gvkey_list)\n",
    "\n",
    "df_all = fundq_df[['gvkey','datadate'] + income_list + blnc_sheet_list]\n",
    "\n",
    "def reorder_cols():\n",
    "    a = ['datadate','gvkey','year','month']\n",
    "    mom = ['mom1m','mom3m','mom6m','mom9m']\n",
    "    prc = ['mrkcap','entval']\n",
    "    ttm_list_tmp = [x + '_ttm' for x in income_list]\n",
    "    mrq_list_tmp = [x + '_mrq' for x in blnc_sheet_list]\n",
    "    mrq_list_tmp.remove('cshoq_mrq')\n",
    "    mrq_list_tmp.remove('dlttq_mrq')\n",
    "    csho = ['csho_1yr_avg']\n",
    "\n",
    "    new_order = a + mom + prc + ttm_list_tmp + mrq_list_tmp + csho\n",
    "    return new_order\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create empty df to be appended for each equity\n",
    "df_all_eq = pd.DataFrame(columns=reorder_cols())\n",
    "\n",
    "run_time_month = datetime.datetime.now().date().month\n",
    "\n",
    "for key in gvkey_list:\n",
    "    #print(\"GVKEY: %s\"%key)\n",
    "    df = df_all[df_all['gvkey'] == key].copy()\n",
    "    df = df.sort_values('datadate')\n",
    "    df = df.set_index('datadate',drop=False)\n",
    "    df = df[~df.index.duplicated(keep='first')]\n",
    "    #print(\"df shape:%g,%g\"%df.shape)\n",
    "    \n",
    "\n",
    "    # get price_df for the current gvkey\n",
    "    price_df = price_df_all[price_df_all['gvkey']==key].copy()\n",
    "    #print(\"price df shape:%g,%g\"%price_df.shape)\n",
    "    \n",
    "    # get stock_split_df for the current gvkey\n",
    "    stock_split_df = stock_split_df_all[stock_split_df_all['gvkey']==key].copy()\n",
    "    #print(\"stock split df shape:%g,%g\"%stock_split_df.shape)\n",
    "    #print(\"\\n\")\n",
    "\n",
    "    # Start data processing\n",
    "    dp = data_processing(lag=3)\n",
    "    \n",
    "    # Add the lag to the date index\n",
    "    df = dp.add_lag(df)\n",
    "    \n",
    "    \n",
    "    # Create new df with monthly frequency (empty)\n",
    "    new_df_empty = dp.create_df_monthly(df)\n",
    "    \n",
    "    # Add ttm and mrq data\n",
    "    ttm_mrq_df = dp.create_ttm_mrq(df,new_df_empty)\n",
    "    #print ttm_mrq_df.head()\n",
    "    \n",
    "    # Adjust for stock split\n",
    "    df_split_adjusted = dp.adjust_cshoq(ttm_mrq_df,stock_split_df)\n",
    "\n",
    "    # Add price information\n",
    "    df_w_price,price_df_for_mom = dp.add_price_features(df_split_adjusted,price_df)\n",
    "    \n",
    "    # Add momentum features\n",
    "    df_w_mom = dp.get_mom(df_w_price,price_df_for_mom,[1,3,6,9])\n",
    "    #print df_w_mom.head()\n",
    "    # Add csho_1_year average\n",
    "    df_w_mom['csho_1yr_avg'] = df_w_mom['cshoq_mrq'].rolling(12,min_periods=1).mean()\n",
    "    \n",
    "    \n",
    "    # Reorder column names\n",
    "    new_order = reorder_cols()\n",
    "\n",
    "    del df,price_df,stock_split_df\n",
    "\n",
    "    df_out = df_w_mom[new_order]\n",
    "\n",
    "    # Fill Nans with 0.0\n",
    "    df_out = df_out.fillna(0.0)\n",
    "    df_out = df_out.reset_index(drop=True)\n",
    "    # Append the current df to the full_df\n",
    "    df_all_eq = df_all_eq.append(df_out,ignore_index=True)\n",
    "    if(run_time_month >= 1 and run_time_month <= 3):\n",
    "        df_all_eq = df_all_eq.loc[df_all_eq['month'] == 12]\n",
    "    elif (run_time_month > 3 and run_time_month <= 6):\n",
    "        df_all_eq = df_all_eq.loc[df_all_eq['month'] == 3]\n",
    "    elif (run_time_month > 6 and run_time_month <= 9):\n",
    "        df_all_eq = df_all_eq.loc[df_all_eq['month'] == 6]\n",
    "    elif (run_time_month > 9 and run_time_month <= 12):\n",
    "        df_all_eq = df_all_eq.loc[df_all_eq['month'] == 9]\n",
    "        \n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    gvkey    datadate   fyear indfmt consol popsrc datafmt   tic curcd  \\\n",
      "0  001690  19810301.0  1981.0   INDL      C      D     STD  AAPL   USD   \n",
      "1  001690  19820301.0  1982.0   INDL      C      D     STD  AAPL   USD   \n",
      "2  001690  19830301.0  1983.0   INDL      C      D     STD  AAPL   USD   \n",
      "3  001690  19840301.0  1984.0   INDL      C      D     STD  AAPL   USD   \n",
      "4  001690  19850301.0  1985.0   INDL      C      D     STD  AAPL   USD   \n",
      "\n",
      "      aco   ...    txach  txbcof  txdc  txditc     txp     txt  xidoc   xint  \\\n",
      "0   0.076   ...      0.0     0.0   0.0   0.523   5.892  12.454    0.0  0.210   \n",
      "1   0.504   ...      0.0     0.0   0.0   6.964   0.268  37.123    0.0  1.300   \n",
      "2   8.067   ...      0.0     0.0   0.0  10.919  12.000  55.466    0.0  1.712   \n",
      "3  23.334   ...      0.0     0.0   0.0  35.785   5.432  69.408    0.0  1.712   \n",
      "4  50.735   ...      0.0     0.0   0.0  63.977  11.301  45.130    0.0  1.712   \n",
      "\n",
      "      xsga  costat  \n",
      "0   26.211       A  \n",
      "1   88.279       A  \n",
      "2  192.851       A  \n",
      "3  347.365       A  \n",
      "4  545.842       A  \n",
      "\n",
      "[5 rows x 79 columns]\n",
      "69.799546957\n"
     ]
    }
   ],
   "source": [
    "# Normalize the momentum features\n",
    "dates = df_all_eq['datadate'].unique()\n",
    "mom_f = ['mom1m','mom3m','mom6m','mom9m']\n",
    "\n",
    "\n",
    "for date in dates:\n",
    "    df_date = df_all_eq[mom_f][df_all_eq['datadate']==date]\n",
    "    ix_dates = df_date.index\n",
    "    df_norm = (df_date - df_date.min())/(df_date.max() - df_date.min())\n",
    "\n",
    "    df_norm = df_norm.fillna(0.0)\n",
    "\n",
    "    df_all_eq.loc[ix_dates,mom_f] = df_norm\n",
    "\n",
    "    del df_date, df_norm\n",
    "\n",
    "    #r = ['gvkey','datadate','fyear']\n",
    "   #a =['aco','act','ao','aoloch','ap','apalch','aqc','at','capx','ceq','che'cogs\tdlc\tdlcch\tdltis\tdltr\tdltt\tdpc\tdv\tepsfx\tepspx\tesub\tfiao\tfincf\tfopo\tib\tibc\tintan\tinvch\tinvt\tivaco\tivaeq\tivao\tivch\tivncf\tivstch\tlco\tlct\tlo\tlt\tmib\tniadj\tnopi\toancf\toiadp\toibdp\tpi\tppent\tprstkc\tpstk\trecch\trect\trevt\tseq\tsiv\tspi\tsppe\tsppiv\tsstk\ttxach\ttxbcof\ttxdc\ttxditc\ttxp\ttxt\txidoc\txint\txsga\tcostat\n",
    "\n",
    "def rereorder_cols():\n",
    "    a = ['datadate','gvkey','fyear','month']\n",
    "    mom = ['mom1m','mom3m','mom6m','mom9m']\n",
    "    prc = ['mrkcap','entval']\n",
    "    ttm_list_tmp = ['sale','cogs','xsga','oiadp','ni','revt','xint','nopi','spi',\n",
    "               'pi','txt','ib','epspx','epsfx']\n",
    "    mrq_list_tmp = ['che','rect','invt','aco','act','ppent','ivaeq','ivao','intan','ao','at',\n",
    "                                'dlc','ap','txp','lco','lct','dltt','txditc','lo','lt','mib',\n",
    "                   'pstk','ceq','seq','csho']\n",
    "    mrq_list_tmp.remove('csho')\n",
    "    mrq_list_tmp.remove('dltt')\n",
    "    csho = ['csho_1yr_avg']\n",
    "\n",
    "    new_order = a + mom + prc + ttm_list_tmp + mrq_list_tmp + csho\n",
    "    return new_order\n",
    "\n",
    "\n",
    "df_all_eq.columns = rereorder_cols()\n",
    "df_all_eq = df_all_eq.drop(['month','mom1m','mom3m','mom6m','mom9m','mrkcap','entval'], 1)\n",
    "\n",
    "\n",
    "cols = df_all_eq.columns.tolist()\n",
    "\n",
    "cols = ['gvkey','datadate','fyear','aco','act','ao','ap','at','ceq','che','cogs','dlc','epsfx','epspx','ib','intan','invt','ivaeq','ivao','lco','lct','lo','lt','mib','oiadp','pi','ppent','pstk','rect','revt','seq','spi','txditc','txp','txt','xint','xsga']\n",
    "remain = ['csho_1yr_avg','ni','sale']\n",
    "left_in_combined_less_impor = ['indfmt','consol','popsrc','datafmt','tic','curcd','costat']\n",
    "left_in_combined_impor = ['aoloch','apalch','aqc','capx','dlcch','dltis','dltr','dltt','dpc','dv','esub','fiao','fincf','fopo','ibc','invch','ivaco','ivch','ivncf','ivstch','niadj','nopi','oancf','oibdp','prstkc','pstk','recch','siv','sppe','sppiv','sstk','txbcof','txdc','xidoc']\n",
    "df_all_eq = df_all_eq[cols]\n",
    "\n",
    "\n",
    "#not_in_compm = [curcd dltty niadjy pstky txbchy]\n",
    "q5 = (\"select gvkey, datadate, indfmt, consol, popsrc, datafmt, tic, costat,\"\n",
    "      \"aolochy, apalchy, aqcy, capxy, dlcchy, dltisy, dltry, dpcy, dvy, esuby, \"\n",
    "      \"fiaoy, fincfy, fopoy, ibcy, invchy, ivacoy, ivchy, ivncfy, ivstchy, nopiy, \"\n",
    "      \"oancfy, oibdpy, prstkcy,  recchy, sivy, sppey, sppivy, sstky, txbcofy, txdcy, xidocy \"\n",
    "    \"from compm.fundq \"\n",
    "    \"where gvkey in (%s) \")%top_20_eq_gvkey\n",
    "others = db.raw_sql(q5)\n",
    "cols3 = ['gvkey', 'datadate','indfmt', 'consol', 'popsrc', 'datafmt', 'tic', 'costat',\n",
    "      'aoloch', 'apalch', 'aqc', 'capx', 'dlcch', 'dltis', 'dltr', 'dpc', 'dv', 'esub',\n",
    "      'fiao', 'fincf', 'fopo', 'ibc', 'invch', 'ivaco', 'ivch', 'ivncf', 'ivstch', 'nopi', \n",
    "      'oancf', 'oibdp', 'prstkc',  'recch', 'siv', 'sppe', 'sppiv', 'sstk', 'txbcof', 'txdc', 'xidoc']\n",
    "#df1 = pd.DataFrame(columns=cols3)\n",
    "others = others.drop(['gvkey', 'datadate'],1)\n",
    "\n",
    "\n",
    "q6 = (\"select gvkey, datadate, curcd, dltt, pstk, niadj,txach \" \n",
    "      \"from compa.funda \"\n",
    "     \"where gvkey in (%s) \")%top_20_eq_gvkey\n",
    "others2 = db.raw_sql(q6)\n",
    "cols4 = ['gvkey', 'datadate', 'curcd', 'dltt', 'pstk', 'niadj','txach'] \n",
    "#df2 = pd.DataFrame(columns=cols4)\n",
    "others2 = others2.drop(['gvkey', 'datadate'],1)\n",
    "\n",
    "df_all_eq =  pd.concat([df_all_eq, others, others2], axis=1)\n",
    "\n",
    "\n",
    "cols = ['gvkey','datadate','fyear','indfmt','consol','popsrc','datafmt','tic','curcd','aco','act','ao','aoloch','ap','apalch','aqc','at','capx','ceq','che','cogs','dlc','dlcch','dltis','dltr','dltt','dpc','dv','epsfx','epspx','esub','fiao','fincf','fopo','ib','ibc','intan','invch','invt','ivaco','ivaeq','ivao','ivch','ivncf','ivstch','lco','lct','lo','lt','mib','niadj','nopi','oancf','oiadp','oibdp','pi','ppent','prstkc','pstk','recch','rect','revt','seq','siv','spi','sppe','sppiv','sstk','txach','txbcof','txdc','txditc','txp','txt','xidoc','xint','xsga','costat']\n",
    "cols2 = ['gvkey','datadate','fyear','aco','act','ao','ap','at','ceq','che','cogs','dlc','epsfx','epspx','ib','intan','invt','ivaeq','ivao','lco','lct','lo','lt','mib','oiadp','pi','ppent','pstk','rect','revt','seq','spi','txditc','txp','txt','xint','xsga',\n",
    "        'indfmt', 'consol', 'popsrc', 'datafmt', 'tic', 'costat',\n",
    "      'aoloch', 'apalch', 'aqc', 'capx', 'dlcch', 'dltis', 'dltr', 'dpc', 'dv', 'esub',\n",
    "      'fiao', 'fincf', 'fopo', 'ibc', 'invch', 'ivaco', 'ivch', 'ivncf', 'ivstch', 'nopi', \n",
    "      'oancf', 'oibdp', 'prstkc',  'recch', 'siv', 'sppe', 'sppiv', 'sstk', 'txbcof', 'txdc', 'xidoc' ,'curcd', 'dltt', 'pstk', 'niadj','txach']\n",
    "\n",
    "df_all_eq.columns = cols2;\n",
    "\n",
    "df_all_eq = df_all_eq[cols]\n",
    "\n",
    "def to_integer(dt_time):\n",
    "    return 10000*dt_time.year + 100*dt_time.month + dt_time.day\n",
    "\n",
    "df_all_eq['datadate'] = df_all_eq['datadate'].apply(to_integer)\n",
    "\n",
    "df_all_eq = df_all_eq.fillna(0.0)\n",
    "df_all_eq = df_all_eq.reset_index(drop=True)\n",
    "\n",
    "print df_all_eq.head()\n",
    "# Output the csv\n",
    "df_all_eq.to_csv(\"top_20_eq_w_3mo_lag1.csv\")\n",
    "exec_time = time() -start_time\n",
    "\n",
    "print exec_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
